<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
  <meta http-equiv="content-type" content="text/html; charset=ISO-8859-1">
  <title>Nestor Guillen's homepage </title>
  <meta name="author" content="Nestor Guillen">
  <link rel="stylesheet" type="text/css" href="main.css">

<script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        messageStyle: "none",
        "HTML-CSS": { availableFonts: ["TeX"] }
      });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script>

</head>

<body>
  
<!-- Header Starts Here  -->  
  
  <div id="navi">
    <table><tbody>
    <td> 
      <img src="portrait2.jpg" align="left">
    </td>
    <td>
      <h1>Nestor Guillen</h1>
      <br>
      Department of Mathematics
      <br>
      Texas State University
      <br>				 	
      Office: MCS 468  Email: nestor@txstate.edu
      <br>
      <br>
      <nav>
        <ul>
    	  <li><a href="vitae.html">Vitae</a></li>
          <li><a href="papers.html">Papers</a></li>
    	  <li><a href="teaching.html">Teaching</a> - <a href="Teaching.html" class="active">MATH 3323</a></li>
    	  <li><a href="https://birdsnfrogs.github.io/" class="external">Blog</a></li>
    	  <li><a href="http://www.ma.utexas.edu/mediawiki/index.php/Starting_page" class="external">Nonlocal Wiki</a></li>			
        </ul>
      </nav>	
  </td>

</tbody></table>
</div>

<!-- Header Ends Here  -->


<div id="main">

<h2>MATH 3323 Differential Equations</h2> 


<h2>Fall 2019 (Sections 04 and 05)</h2>

<ul><font size="+1" color=#000>
<il>

From the course catalog: "A course covering solutions to the more common types of ordinary differential equations, especially those of first and second order, with emphasis on geometrical and physical interpretations". 

<br>	
<br>
<strong>Prerequisites:</strong> Differential and integral calculus (limits, differentiation and integration techniques, series, basic Cartesian geometry). Familiarity with linear alegebra and/or multivariable calculus is very helpful but not required.
<br>
<br>
<strong>Textbook:</strong> Elementary Differential Equations and Boundary Value Problems. Boyce, DiPrima, Meade. 11th Edition. 
<br>
<br>
<strong>Lecture Times</strong>: Monday-Wednesday (Section 03) and Monday-Wednesday (Section 04) 
<br>
<strong>Office Hours</strong>: Monday and Wednesday 10 am -12 pm.
<br>

<br>
<strong>Evaluation:</strong> 

There will be 3 exams throughout the semester and 1 final, as well as weekly problem sets.

There will be 14 problem sets total, all due on Mondays (except the first one, which will be due on Wednesday September 4th

Exam Dates: September 30th, October 21st, November 18th.

Final Date: TBD.

<br>

<strong>Grading scheme:</strong>

<br>
Solutions to problem sets are to be submitted in latex format, via email. No late problem sets will be accepted. Out of 8 problem sets, lowest two grades will be dropped in computing the total.
<br>
The project will be done in teams of two people (if needed, a couple of teams with 3 people will be allowed)
<br>
<br>
<strong>Updated! (November 10th)</strong> Important dates for the project: Tuesday of 11th week. Thursday of 15th week.
</il>

</font></ul>

<br>

<h2><font size="+2" color=#000><strong>Problem sets</strong></font></h2>

<font size="+1" color=#000> 	<a href="697/pset1.pdf">First</a>&nbsp;&nbsp;<font size="+1" color=#000> 	<a href="697/pset2.pdf">Second</a>&nbsp;&nbsp;<font size="+1" color=#000> 	<a href="697/pset3.pdf">Third</a>&nbsp;&nbsp;<a href="697/pset4.pdf">Fourth</a>&nbsp;&nbsp;<a href="697/pset5.pdf">Fifth</a>&nbsp;&nbsp;
<br>
<br>
<h2><font size="+2" color=#000><strong>Lecture plan and slides</strong> (updated 10/23)</font></h2> 

<ul>

<li><font size="+1" color=#000><b>Week 1.</b> &nbsp;<a href="697/697Week1.pdf">(Slides)</a> 
<br>	
Tuesday class: Review prerequisites, basic facts, and notation. Function approximation/estimation as motivation. Four terms: supervised/unsupervised learning, regression, and classification. A glance at the latter half of the courses: the calculus of variations, partial differential equations, and optimization.
<br>
<i>Reading:</i> (From HTF) Introduction, Sections 2.1 and 2.2. 
<br>
<br>
Thursday class: Least squares versus $k$-nearest neighbor. Statistical decision theory. 
<br>
<i>Reading:</i> (From HTF) Sections 2.3 and 2.4.
<br>
<br>
</font></li>


<li><font size="+1" color=#000><b>Week 2.</b>  &nbsp;<a href="697/697Week2.pdf">(Slides)</a> 
<br>
Tuesday class: Curse of dimensionality and how it affects $k$-NN and least squares. Mean squared error and expected prediction error. Statistical models and restricted function classes.
<br>
<i>Reading:</i>  (From HTF) Sections 2.6 and 2.7. 
<br>
<br>
Thursday class:  Maximum likelihood. Least squares and ML for additive models. More about restricted regression models: roughness penalty, kernel methods, and local regression.
<br>
<i>Reading:</i> (From HTF) Sections 2.8.1 and 2.8.2.

<br>
<br>	
</font></li>

<li><font size="+1" color=#000><b>Week 3.</b> &nbsp;<a href="697/697Week3.pdf">(Slides)</a> 
<br>
Tuesday class: Model selection: Training error versus generalization error. Parameter inference: Gaussian model for the error, and how $\hat \beta$ is distributed. The Gauss Markov Theorem. 
<br>
<i>Reading:</i> (From HTF) Sections 2.9, 3.1, and Section 3.2.2.
<br>
<br>
Thursday class: The singular value decomposition and least squares. Univariate versus Multivariate regression. Shortcomings of least squares and the bias-variance dichotomy. Subset selection. Ridge regression and intro to the Lasso.
<br>
<i>Reading:</i> (From HTF) Section 3.2.3, 3.3.1, and Section 3.4.1 up to page 64.
<br>
<br>		
</font></li>

<li><font size="+1" color=#000><b>Week 4.</b> &nbsp;<a href="697/697Week4.pdf">(Slides)</a> 
<br>
Tuesday class: A rapid course on convex functions (the Legendre transform, the subdifferential, critical points and the subdifferential). The Lasso and characterization of minimizers through the subdifferential. Example: the Lasso for an orthogonal input matrix and the shrinkage operator. 
<br>
<i>Reading:</i> (From HTF) Rest of Section 3.4.1, Section 3.4.2.
<br>
<br>
Thursday class: Discussion of the first problem set (distributions, convolutions, approximations to the identity). Lasso as a constrained quadratic program. The geometry of $\ell^1$ and how it explains the sparsity of Lasso solutions.
<br>
<i>Reading:</i> (From HTF) Section 3.4.3 and Section 3.6.
<br>
<br>	
</font></li>

<li><font size="+1" color=#000><b>Week 5-6.</b> &nbsp;(No class)
<br>
<br>
</font></li>

<li><font size="+1" color=#000><b>Week 7.</b> &nbsp;<a href="697/697Week7.pdf">(Slides)</a> 
<br>
Tuesday class: Using the Lasso with least squares to minimize bias. Inference when $p>>N$ via the Dantzig selector. The Restricted Isometry Property and a Theorem of Candes and Tao. Summary of linear regression. Basics of linear classification: regression via indicator matrices, masking.
<br>
<i>Reading:</i> (From HTF) Sections 3.8.3 and 3.8.4, Sections 4.1 and 4.2.
<br>
<br>
Thursday class: Linear and quadratic discriminant analysis with Gaussian mixtures. Logistic regression. 
<br>
<i>Reading:</i> (From HTF) Section 4.3 (up to page 112), Sections 4.4.1.
<br>	
<br>
</font></li>


<li><font size="+1" color=#000><b>Week 8.</b> &nbsp;<a href="697/697Week8.pdf">(Slides)</a> 
<br>
Tuesday class: More on Logistic Regression and gradient descent. Logistic regression versus LDA. Rosenblatt's separating hyperplane algorithm and Vapnik's optimality criterion.
<br>
<i>Reading:</i> (From HTF) Sections 4.4.1, 4.4.5, and Section 4.5
<br>
<br>
Thursday class: A few thoughts on elliptic PDE and the Calculus of Variations. The Laplacian in $\mathbb{R}^d$ and its many versions. Fourier series, eigenfunctions of the second derivative, and the heat equation.

<br>
<i>Reading:</i> (From HTF) Sections 7.1, 7.2, 7.4 and 7.5.
<br>	
<br>
</font></li>


<li><font size="+1" color=#000><b>Week 9.</b> &nbsp;<a href="697/697Week9.pdf">(Slides)</a> 
<br>
Tuesday class: More on the calculus of variations: the Euler-Lagrange equation and Dirichlet's principle for harmonic functions. Historical detour: Hilbert's 19th problem. The smoothing effect of the heat equation. The mean value property for harmonic functions.
<br>
<i>Reading:</i> N.A.
<br>
<br>
Thursday class: The strong maximum principle. The comparison principle for Laplace's equation and its consequences. The fractional Laplacian. 
<br>
<i>Reading:</i> N.A.
<br>	
<br>
</font></li>

<li><font size="+1" color=#000><b>Week 10.</b> &nbsp;<a href="697/697Week10.pdf">(Slides)</a> 
<br>
Tuesday class: Infinite differentiability of harmonic functions and interior derivative estimates. Graphs, their weights and graph Laplacians.

<br>
<i>Reading:</i> N.A.
<br>
<br>
Thursday class: The strong maximum principle in a graph. Measuring smoothness for functions in a graph. Spectral properties of the combinatorial Laplacian, and its eigenfunction decomposition. The heat kernel in a graph.

<br>
<i>Reading:</i> N.A.
<br>	
<br>
</font></li>

<li><font size="+1" color=#000><b>Week 11.</b> &nbsp;<a href="697/697Week11.pdf">(Slides)</a> 
<br>
Tuesday class: The Dirichlet problem on a grpah. Semi-supervised learning and harmonic minimization.

<br>
<i>Reading:</i> N.A.
<br>
<br>
Thursday class: Spectral representation of data.  Spectral clustering and the Shi-Malik normalized cut functional.

<br>
<i>Reading:</i> N.A.
<br>
<br>	
</font></li>


<li><font size="+1" color=#000><b>Week 12.</b> &nbsp;<a href="697/697Week12.pdf">(Slides)</a> 
<br>
Tuesday class: More clustering: Dissimilarity matrices, the $K$-means algorithm and an example in vector quantization. A comparison of various 'metrics' over distributions: $L^p$, Total Variation, the Earth Mover Distance, the Kullback-Leibler divergence.

<br>
<i>Reading:</i> N.A.
<br>
<br>
Thursday class: Basics of optimal transport. The Monge Problem and Kantorovich Problems in the discrete and continuous settings. Brenier's theorem and the role of convex potentials in optimal transport. Transport with a discrete target measure.   

<br>
<i>Reading:</i> N.A.
<br>	
</font></li>


</ul>

<br>
<br>
<br>
</div>


</body>

</html>



